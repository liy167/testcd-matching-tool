"""
ç½‘é¡µç‰ˆæ£€æŸ¥é¡¹ç›®åŒ¹é…å™¨
ä½¿ç”¨Streamlitåˆ›å»ºWebç•Œé¢
"""

import streamlit as st
from lab_test_matcher import LabTestMatcher
import json
import re
import os

# å°è¯•ä».envæ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¦‚æœå®‰è£…äº†python-dotenvï¼‰
try:
    from dotenv import load_dotenv
    load_dotenv()  # åŠ è½½.envæ–‡ä»¶
except ImportError:
    # å¦‚æœæ²¡æœ‰å®‰è£…python-dotenvï¼Œè·³è¿‡
    pass

# ç¿»è¯‘åŠŸèƒ½ï¼ˆä½¿ç”¨deep-translatorï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ç®€å•å›é€€ï¼‰
try:
    from deep_translator import GoogleTranslator
    HAS_TRANSLATOR = True
except ImportError:
    HAS_TRANSLATOR = False

# ç¿»è¯‘ç¼“å­˜ï¼ˆé¿å…é‡å¤ç¿»è¯‘ç›¸åŒæ–‡æœ¬ï¼‰
_translation_cache = {}

def translate_text(text: str) -> str:
    """
    ç¿»è¯‘æ–‡æœ¬ä¸ºä¸­æ–‡
    
    Args:
        text: è¦ç¿»è¯‘çš„æ–‡æœ¬
        
    Returns:
        ç¿»è¯‘åçš„ä¸­æ–‡æ–‡æœ¬ï¼Œå¦‚æœç¿»è¯‘å¤±è´¥åˆ™è¿”å›åŸæ–‡æœ¬
    """
    if not text or not text.strip():
        return text
    
    # å¦‚æœæ–‡æœ¬å·²ç»æ˜¯ä¸­æ–‡ï¼ˆåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼‰ï¼Œç›´æ¥è¿”å›
    if re.search(r'[\u4e00-\u9fff]', text):
        return text
    
    # æ£€æŸ¥ç¼“å­˜
    if text in _translation_cache:
        return _translation_cache[text]
    
    # å¦‚æœæ–‡æœ¬ä¸»è¦æ˜¯è‹±æ–‡ï¼Œå°è¯•ç¿»è¯‘
    if HAS_TRANSLATOR:
        try:
            # åªç¿»è¯‘è‹±æ–‡éƒ¨åˆ†ï¼Œä¿ç•™åˆ†å·åˆ†éš”çš„ç»“æ„
            if ';' in text:
                parts = text.split(';')
                translated_parts = []
                for part in parts:
                    part = part.strip()
                    if part and not re.search(r'[\u4e00-\u9fff]', part):
                        try:
                            translator = GoogleTranslator(source='en', target='zh')
                            translated = translator.translate(part)
                            translated_parts.append(f"{part} ({translated})")
                        except:
                            translated_parts.append(part)
                    else:
                        translated_parts.append(part)
                result = '; '.join(translated_parts)
            else:
                try:
                    translator = GoogleTranslator(source='en', target='zh')
                    translated = translator.translate(text)
                    result = f"{text} ({translated})"
                except:
                    result = text
            
            # ç¼“å­˜ç»“æœ
            _translation_cache[text] = result
            return result
        except Exception:
            return text
    else:
        # å¦‚æœæ²¡æœ‰ç¿»è¯‘å™¨ï¼Œè¿”å›åŸæ–‡æœ¬
        return text

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ£€æŸ¥é¡¹ç›®åŒ¹é…å™¨",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–åŒ¹é…å™¨ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åŠ è½½ï¼‰
@st.cache_resource
def get_matcher():
    """è·å–åŒ¹é…å™¨å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    return LabTestMatcher()

# æ ‡é¢˜
st.title("ğŸ”¬ æ£€æŸ¥é¡¹ç›®TEST - > TESTCD æŸ¥è¯¢å·¥å…·")
st.markdown("---")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ é…ç½®")
    top_k = st.slider("è¿”å›ç»“æœæ•°é‡", min_value=1, max_value=20, value=10, step=1)
    st.markdown("---")
    st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥æ£€æŸ¥é¡¹ç›®åç§°ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
    2. ç‚¹å‡»"æœç´¢"æŒ‰é’®æˆ–æŒ‰Enteré”®
    3. æŸ¥çœ‹åŒ¹é…ç»“æœï¼ŒæŒ‰ç›¸ä¼¼åº¦æ’åº
    """)

# åˆå§‹åŒ–åŒ¹é…å™¨
try:
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–åŒ¹é…å™¨..."):
        matcher = get_matcher()
    st.success("åŒ¹é…å™¨åˆå§‹åŒ–æˆåŠŸï¼")
except Exception as e:
    st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
    st.stop()

# æœç´¢è¾“å…¥
st.subheader("ğŸ” æœç´¢")
query = st.text_input(
    "è¾“å…¥æ£€æŸ¥é¡¹ç›®åç§°ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰",
    placeholder="ä¾‹å¦‚ï¼šè¡€çº¢è›‹ç™½ æˆ– Hemoglobin",
    label_visibility="collapsed"
)

# æœç´¢æŒ‰é’®
col1, col2 = st.columns([1, 10])
with col1:
    search_button = st.button("æœç´¢", type="primary", use_container_width=True)

# æ‰§è¡Œæœç´¢
if search_button or query:
    if query.strip():
        try:
            with st.spinner(f"æ­£åœ¨æœç´¢ '{query}'..."):
                results = matcher.search_top_matches(query, top_k=top_k)
            
            if results:
                st.markdown("---")
                # æ£€æŸ¥æ˜¯å¦ä¸ºç²¾ç¡®åŒ¹é…
                is_exact_match = results[0].get('is_exact_match', False)
                
                if is_exact_match:
                    st.subheader(f"âœ… ç²¾ç¡®åŒ¹é…ç»“æœï¼ˆå…± {len(results)} æ¡ï¼‰")
                    st.info("ğŸ¯ åœ¨TEST_TESTCD_mapping.xlsxä¸­æ‰¾åˆ°ç²¾ç¡®åŒ¹é…ï¼")
                else:
                    st.subheader(f"ğŸ“Š è¯­ä¹‰åŒ¹é…ç»“æœï¼ˆå…± {len(results)} æ¡ï¼‰")
                
                # æ˜¾ç¤ºè¡¨æ ¼
                import pandas as pd
                df_data = []
                
                if is_exact_match:
                    # ç²¾ç¡®åŒ¹é…ï¼šæ˜¾ç¤ºTESTDSã€TESTS_CNã€TESTS_ENåˆ—ï¼ˆæ¥è‡ªTEST_TESTCD_mapping.xlsxï¼‰
                    for i, result in enumerate(results, 1):
                        df_data.append({
                            "æ’å": i,
                            "ç›¸ä¼¼åº¦": f"{result['similarity']:.4f}",
                            "TESTDS": result.get('testds_value', ''),
                            "TESTS_CN": result.get('tests_cn_value', ''),
                            "TESTS_EN": result.get('tests_en_value', '')
                        })
                else:
                    # è¯­ä¹‰åŒ¹é…ï¼šæ˜¾ç¤ºEã€Fã€Håˆ—
                    for i, result in enumerate(results, 1):
                        # Fåˆ—ï¼šä¼˜å…ˆä½¿ç”¨æ˜ å°„æ–‡ä»¶ä¸­çš„ä¸­æ–‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¿»è¯‘API
                        f_value = result.get('f_value', '')
                        f_cn_value = result.get('f_cn_value', '')
                        
                        if f_cn_value:
                            # å¦‚æœæ˜ å°„æ–‡ä»¶ä¸­æœ‰ä¸­æ–‡ï¼Œæ˜¾ç¤ºï¼šè‹±æ–‡ (ä¸­æ–‡)
                            f_value_display = f"{f_value} ({f_cn_value})" if f_value else f_cn_value
                        else:
                            # å¦‚æœæ²¡æœ‰æ˜ å°„æ–‡ä»¶çš„ä¸­æ–‡ï¼Œä½¿ç”¨ç¿»è¯‘API
                            f_value_display = translate_text(f_value)
                        
                        # Håˆ—ï¼šä½¿ç”¨ç¿»è¯‘API
                        h_value = result.get('h_value', '')
                        h_value_with_translation = translate_text(h_value)
                        
                        df_data.append({
                            "æ’å": i,
                            "ç›¸ä¼¼åº¦": f"{result['similarity']:.4f}",
                            "CDISC Submission Value (E)": result.get('e_value', ''),
                            "CDISC Synonym(s) (F)": f_value_display,
                            "NCI Preferred Term (H)": h_value_with_translation
                        })
                
                df = pd.DataFrame(df_data)
                st.dataframe(df, use_container_width=True, hide_index=True)
                
                # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆå¯å±•å¼€ï¼‰
                with st.expander("ğŸ“‹ æŸ¥çœ‹JSONæ ¼å¼ç»“æœ"):
                    json_result = matcher.format_results_json(results)
                    st.json(json_result)
                
                # ä¸‹è½½ç»“æœ
                json_str = json.dumps(json_result, indent=2, ensure_ascii=False)
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½JSONç»“æœ",
                    data=json_str,
                    file_name=f"search_results_{query}.json",
                    mime="application/json"
                )
            else:
                st.warning("æœªæ‰¾åˆ°åŒ¹é…ç»“æœã€‚")
                
        except Exception as e:
            st.error(f"æœç´¢å¤±è´¥: {e}")
            st.exception(e)
    else:
        st.warning("è¯·è¾“å…¥æŸ¥è¯¢æ–‡æœ¬")

# é¡µè„š
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>æ£€æŸ¥é¡¹ç›®TEST - > TESTCD æŸ¥è¯¢å·¥å…· | ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…</div>",
    unsafe_allow_html=True
)

